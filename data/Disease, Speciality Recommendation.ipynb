{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6fed95-139d-4f8d-bbef-c940cb82f5ea",
   "metadata": {},
   "source": [
    "# Disease, Speciality Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdcfaca-c0c9-44f6-a2ae-3107f2d178d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ada8ab-c5e8-4c87-8d56-55ee1d97c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Original_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beb1404-c3d1-4ed8-b64d-ccde2969610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a2495-a16e-42ab-a2be-b2ac39f33716",
   "metadata": {},
   "source": [
    "## Finding unique values across all the symptoms column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d44be47-c84d-46b4-93d0-84d11fe37636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Symptom_1',\n",
       " 'Symptom_2',\n",
       " 'Symptom_3',\n",
       " 'Symptom_4',\n",
       " 'Symptom_5',\n",
       " 'Symptom_6',\n",
       " 'Symptom_7',\n",
       " 'Symptom_8',\n",
       " 'Symptom_9',\n",
       " 'Symptom_10',\n",
       " 'Symptom_11',\n",
       " 'Symptom_12',\n",
       " 'Symptom_13',\n",
       " 'Symptom_14',\n",
       " 'Symptom_15',\n",
       " 'Symptom_16',\n",
       " 'Symptom_17']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_to_check = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if col != \"Disease\":\n",
    "        column_to_check.append(col) \n",
    "\n",
    "column_to_check\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42144e41-8068-4e66-bf50-9798eed647dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms = data.iloc[:, 1:].values.flatten() # Extracts values from all columns except the first, flattens them into a 1D array, and assigns them to symptoms.\n",
    "symptoms = list(set(symptoms)) # Converts symptoms to a set (to remove duplicates) and then back to a list.\n",
    "# symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8800639-14f3-48aa-b31a-149cc3a10c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac12cc-ce0c-48a1-b0b6-c8bff0189d02",
   "metadata": {},
   "source": [
    "## Convert Symptoms to Binary Columns\n",
    "\n",
    "### For each symptom, it checks each row (excluding the first column) to see if that symptom is present.\n",
    "### The lambda row: int(symptom in row.values) expression returns 1 if the symptom is in the row, otherwise 0.\n",
    "### This creates a new column in data for each symptom, marking 1 if present in the row, or 0 if not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ede8b3f-2f8e-4022-bcc0-0b522d2648fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n",
      "/tmp/ipykernel_15816/3550304128.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1)\n"
     ]
    }
   ],
   "source": [
    "for symptom in symptoms:\n",
    "    data[symptom] = data.iloc[:, 1 : ].apply(lambda row: int(symptom in row.values), axis=1) \n",
    "\n",
    "data_v = data.drop(columns=column_to_check) # Drops the columns specified in column_to_check from data to create a new DataFrame data_v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7ef1d3-bbe9-4cd4-b4e9-af58d6d154bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a11f15-632b-4242-bb7d-ecadfb566f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c761d08b-7d89-4771-9956-f2097ade87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v = data_v.loc[:, data_v.columns.notna()] # Remove Columns with NaN Names: row and column labels\n",
    "# data_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188d795f-9fdb-4db8-8ad6-e7dca7e75617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6720265d-fc8f-4e07-ba03-f79de8496410",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v.columns = data_v.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a89d7e3-efba-4355-93c5-2e66ff17bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_v.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02664157-086b-45fb-9112-ef46ca39e992",
   "metadata": {},
   "source": [
    "## Encoding Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc9d690-4b18-4aa3-8ed6-3adb074cbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_v.drop(columns=\"Disease\", axis = 1)\n",
    "y = data_v[\"Disease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569e7bd6-5116-43a0-a412-e7e187175e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "510792a3-530b-4c26-9ba2-dbe083d503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b8df1a3-29b0-4c4b-a20c-5e28a3305080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "for i in ['Disease']:\n",
    "    data_v[i] = le.fit_transform(data_v[i])\n",
    "Y = le.transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa2ed8c4-15e8-4660-a739-d746659d9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d83f8e31-7a55-4fd8-93c8-67391da99247",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee518cb9-d927-4de3-839b-63231942970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b0fc5a3-40e0-49b8-b1ee-bf721a9b97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4b707-0ffb-485c-bb8f-09204fcff39f",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2b7ce7d-bb9b-4386-8a4e-ab3c60bbdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0efe732b-d203-4ad3-89dc-eabb515c19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "    \n",
    "    # Save the model\n",
    "    pickle.dump(model, open('models/Logistic_Regression_model.pkl', 'wb'))\n",
    "    print(\"Model saved as 'models/Logistic_Regression_model.pkl'\")\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# 2. Decision Tree\n",
    "def train_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the model\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Decision Tree Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "    \n",
    "    # Save the model\n",
    "    pickle.dump(model, open('models/Decision_Tree_model.pkl', 'wb'))\n",
    "    print(\"Model saved as 'models/Decision_Tree_model.pkl'\")\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# 3. Random Forest\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Random Forest Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "    # Save the model\n",
    "    pickle.dump(model, open('models/Random_Forest_model.pkl', 'wb'))\n",
    "    print(\"Model saved as 'models/Random_Forest_model.pkl'\")\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# 4. Support Vector Machine\n",
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the model\n",
    "    model = SVC(probability=True, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"SVM Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "    \n",
    "    # Save the model\n",
    "    pickle.dump(model, open('models/SVM_model.pkl', 'wb'))\n",
    "    print(\"Model saved as 'models/SVM_model.pkl'\")\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# 5. Naive Bayes\n",
    "def train_naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the model\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "    \n",
    "    # Save the model\n",
    "    pickle.dump(model, open('models/Naive_Bayes_model.pkl', 'wb'))\n",
    "    print(\"Model saved as 'models/Naive_Bayes_model.pkl'\")\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# 6. K-Nearest Neighbors\n",
    "def train_knn(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the model\n",
    "    model = KNeighborsClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"K-Nearest Neighbors Accuracy:\", accuracy)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "    \n",
    "    # Save the model\n",
    "    pickle.dump(model, open('models/KNN_model.pkl', 'wb'))\n",
    "    print(\"Model saved as 'models/KNN_model.pkl'\")\n",
    "    \n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13b37ac6-2495-4b30-9b9c-cce19f6f4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train all models\n",
    "def train_all_models(X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    print(\"Training Logistic Regression...\")\n",
    "    results['Logistic Regression'] = train_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nTraining Decision Tree...\")\n",
    "    results['Decision Tree'] = train_decision_tree(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nTraining Random Forest...\")\n",
    "    results['Random Forest'] = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nTraining SVM...\")\n",
    "    results['SVM'] = train_svm(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nTraining Naive Bayes...\")\n",
    "    results['Naive Bayes'] = train_naive_bayes(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nTraining KNN...\")\n",
    "    results['KNN'] = train_knn(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21518379-20e6-48c9-9d05-f4296a98bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        41\n",
      "           9       1.00      1.00      1.00        36\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       1.00      1.00      1.00        36\n",
      "          12       1.00      1.00      1.00        36\n",
      "          13       1.00      1.00      1.00        39\n",
      "          14       1.00      1.00      1.00        33\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      1.00      1.00        33\n",
      "          17       1.00      1.00      1.00        37\n",
      "          18       1.00      1.00      1.00        44\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        38\n",
      "          21       1.00      1.00      1.00        32\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        44\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00        39\n",
      "          26       1.00      1.00      1.00        33\n",
      "          27       1.00      1.00      1.00        35\n",
      "          28       1.00      1.00      1.00        36\n",
      "          29       1.00      1.00      1.00        40\n",
      "          30       1.00      1.00      1.00        41\n",
      "          31       1.00      1.00      1.00        35\n",
      "          32       1.00      1.00      1.00        35\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00        33\n",
      "          35       1.00      1.00      1.00        35\n",
      "          36       1.00      1.00      1.00        34\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        40\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "Model saved as 'models/Logistic_Regression_model.pkl'\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        41\n",
      "           9       1.00      1.00      1.00        36\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       1.00      1.00      1.00        36\n",
      "          12       1.00      1.00      1.00        36\n",
      "          13       1.00      1.00      1.00        39\n",
      "          14       1.00      1.00      1.00        33\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      1.00      1.00        33\n",
      "          17       1.00      1.00      1.00        37\n",
      "          18       1.00      1.00      1.00        44\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        38\n",
      "          21       1.00      1.00      1.00        32\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        44\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00        39\n",
      "          26       1.00      1.00      1.00        33\n",
      "          27       1.00      1.00      1.00        35\n",
      "          28       1.00      1.00      1.00        36\n",
      "          29       1.00      1.00      1.00        40\n",
      "          30       1.00      1.00      1.00        41\n",
      "          31       1.00      1.00      1.00        35\n",
      "          32       1.00      1.00      1.00        35\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00        33\n",
      "          35       1.00      1.00      1.00        35\n",
      "          36       1.00      1.00      1.00        34\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        40\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "Model saved as 'models/Decision_Tree_model.pkl'\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        41\n",
      "           9       1.00      1.00      1.00        36\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       1.00      1.00      1.00        36\n",
      "          12       1.00      1.00      1.00        36\n",
      "          13       1.00      1.00      1.00        39\n",
      "          14       1.00      1.00      1.00        33\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      1.00      1.00        33\n",
      "          17       1.00      1.00      1.00        37\n",
      "          18       1.00      1.00      1.00        44\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        38\n",
      "          21       1.00      1.00      1.00        32\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        44\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00        39\n",
      "          26       1.00      1.00      1.00        33\n",
      "          27       1.00      1.00      1.00        35\n",
      "          28       1.00      1.00      1.00        36\n",
      "          29       1.00      1.00      1.00        40\n",
      "          30       1.00      1.00      1.00        41\n",
      "          31       1.00      1.00      1.00        35\n",
      "          32       1.00      1.00      1.00        35\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00        33\n",
      "          35       1.00      1.00      1.00        35\n",
      "          36       1.00      1.00      1.00        34\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        40\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "Model saved as 'models/Random_Forest_model.pkl'\n",
      "\n",
      "Training SVM...\n",
      "SVM Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        41\n",
      "           9       1.00      1.00      1.00        36\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       1.00      1.00      1.00        36\n",
      "          12       1.00      1.00      1.00        36\n",
      "          13       1.00      1.00      1.00        39\n",
      "          14       1.00      1.00      1.00        33\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      1.00      1.00        33\n",
      "          17       1.00      1.00      1.00        37\n",
      "          18       1.00      1.00      1.00        44\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        38\n",
      "          21       1.00      1.00      1.00        32\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        44\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00        39\n",
      "          26       1.00      1.00      1.00        33\n",
      "          27       1.00      1.00      1.00        35\n",
      "          28       1.00      1.00      1.00        36\n",
      "          29       1.00      1.00      1.00        40\n",
      "          30       1.00      1.00      1.00        41\n",
      "          31       1.00      1.00      1.00        35\n",
      "          32       1.00      1.00      1.00        35\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00        33\n",
      "          35       1.00      1.00      1.00        35\n",
      "          36       1.00      1.00      1.00        34\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        40\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "Model saved as 'models/SVM_model.pkl'\n",
      "\n",
      "Training Naive Bayes...\n",
      "Naive Bayes Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        41\n",
      "           9       1.00      1.00      1.00        36\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       1.00      1.00      1.00        36\n",
      "          12       1.00      1.00      1.00        36\n",
      "          13       1.00      1.00      1.00        39\n",
      "          14       1.00      1.00      1.00        33\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      1.00      1.00        33\n",
      "          17       1.00      1.00      1.00        37\n",
      "          18       1.00      1.00      1.00        44\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        38\n",
      "          21       1.00      1.00      1.00        32\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        44\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00        39\n",
      "          26       1.00      1.00      1.00        33\n",
      "          27       1.00      1.00      1.00        35\n",
      "          28       1.00      1.00      1.00        36\n",
      "          29       1.00      1.00      1.00        40\n",
      "          30       1.00      1.00      1.00        41\n",
      "          31       1.00      1.00      1.00        35\n",
      "          32       1.00      1.00      1.00        35\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00        33\n",
      "          35       1.00      1.00      1.00        35\n",
      "          36       1.00      1.00      1.00        34\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        40\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Model saved as 'models/Naive_Bayes_model.pkl'\n",
      "\n",
      "Training KNN...\n",
      "K-Nearest Neighbors Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       1.00      1.00      1.00        37\n",
      "           4       1.00      1.00      1.00        36\n",
      "           5       1.00      1.00      1.00        40\n",
      "           6       1.00      1.00      1.00        42\n",
      "           7       1.00      1.00      1.00        45\n",
      "           8       1.00      1.00      1.00        41\n",
      "           9       1.00      1.00      1.00        36\n",
      "          10       1.00      1.00      1.00        32\n",
      "          11       1.00      1.00      1.00        36\n",
      "          12       1.00      1.00      1.00        36\n",
      "          13       1.00      1.00      1.00        39\n",
      "          14       1.00      1.00      1.00        33\n",
      "          15       1.00      1.00      1.00        33\n",
      "          16       1.00      1.00      1.00        33\n",
      "          17       1.00      1.00      1.00        37\n",
      "          18       1.00      1.00      1.00        44\n",
      "          19       1.00      1.00      1.00        31\n",
      "          20       1.00      1.00      1.00        38\n",
      "          21       1.00      1.00      1.00        32\n",
      "          22       1.00      1.00      1.00        36\n",
      "          23       1.00      1.00      1.00        44\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00        39\n",
      "          26       1.00      1.00      1.00        33\n",
      "          27       1.00      1.00      1.00        35\n",
      "          28       1.00      1.00      1.00        36\n",
      "          29       1.00      1.00      1.00        40\n",
      "          30       1.00      1.00      1.00        41\n",
      "          31       1.00      1.00      1.00        35\n",
      "          32       1.00      1.00      1.00        35\n",
      "          33       1.00      1.00      1.00        33\n",
      "          34       1.00      1.00      1.00        33\n",
      "          35       1.00      1.00      1.00        35\n",
      "          36       1.00      1.00      1.00        34\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        40\n",
      "          39       1.00      1.00      1.00        34\n",
      "          40       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00      1476\n",
      "   macro avg       1.00      1.00      1.00      1476\n",
      "weighted avg       1.00      1.00      1.00      1476\n",
      "\n",
      "Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "Model saved as 'models/KNN_model.pkl'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': (LogisticRegression(max_iter=1000), 1.0),\n",
       " 'Decision Tree': (DecisionTreeClassifier(random_state=42), 1.0),\n",
       " 'Random Forest': (RandomForestClassifier(random_state=42), 1.0),\n",
       " 'SVM': (SVC(probability=True, random_state=42), 1.0),\n",
       " 'Naive Bayes': (GaussianNB(), 1.0),\n",
       " 'KNN': (KNeighborsClassifier(), 1.0)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38757123-f830-4651-bc59-93ab6578977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic Regression': \n",
    "              {\"model\": LogisticRegression()},\n",
    "              \n",
    "              'Decision Tree': \n",
    "              {\"model\": DecisionTreeClassifier()},\n",
    "              \n",
    "              'Random Forest': \n",
    "              {\"model\": RandomForestClassifier()},\n",
    "              \n",
    "              'SVM':\n",
    "              {\"model\": SVC(probability=True)},\n",
    "              \n",
    "              'NaiveBayes' :\n",
    "              {\"model\": GaussianNB()},\n",
    "              \n",
    "              'K-Nearest Neighbors' :\n",
    "              {\"model\": KNeighborsClassifier()},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0010e14-0fe7-4bf2-a4c7-a0e3bb33812c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0\n",
      "Logistic Regression Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Decision Tree Accuracy: 1.0\n",
      "Decision Tree Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n",
      "SVM Accuracy: 1.0\n",
      "SVM Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n",
      "NaiveBayes Accuracy: 1.0\n",
      "NaiveBayes Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n",
      "K-Nearest Neighbors Accuracy: 1.0\n",
      "K-Nearest Neighbors Confusion Matrix:\n",
      "[[30,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 34,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 35, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 40,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 34,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 26]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, values in models.items():\n",
    "    # Train the model\n",
    "    values[\"model\"].fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    predictions = values[\"model\"].predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fcf00-3186-4357-af5f-7b162762c246",
   "metadata": {},
   "source": [
    "- single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d83d18c-8a7f-47de-bc70-36498bd7573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88dd5e9e-0490-485a-a9c5-887003d42696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2845d09-08f1-4ddc-8fb5-075b2a6c135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save svc\n",
    "import pickle\n",
    "pickle.dump(model,open('Logistic_Regression_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dda18cc-3a25-4ba0-87e7-896af8c54343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "lr = pickle.load(open('Logistic_Regression_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f0429f5-235a-43ff-acc9-01f763629214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted disease : [26]\n",
      "Actual Disease : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predicted disease :\",lr.predict(X_test.iloc[0].values.reshape(1,-1)))\n",
    "print(\"Actual Disease :\", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5189790e-c371-46ba-92df-159d19d84dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted disease : [18]\n",
      "Actual Disease : 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "print(\"predicted disease :\",lr.predict(X_test.iloc[100].values.reshape(1,-1)))\n",
    "print(\"Actual Disease :\", y_test[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7e649-81f6-4265-a6d7-c79be0ae8b63",
   "metadata": {},
   "source": [
    "## Map Description and Specialist for the Disease Predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39705785-f360-4fe6-a38d-a87db082dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "doct_data = pd.read_csv(\"Doctor_Versus_Disease.csv\", encoding='latin1', names=['Disease','Specialist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdb50419-b535-46c6-be97-54f3b2f3bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doct_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72795f75-19b2-4ae1-a7a2-f98fba3150a3",
   "metadata": {},
   "source": [
    "## Doctor name is wrong for Disease - Tuberculosis. Replace to Pulmonologist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4460de3-49ee-4e7c-982a-bf69080cec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "doct_data['Specialist'] = np.where((doct_data['Disease']=='Tuberculosis'),'Pulmonologist', doct_data['Specialist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9feb322-3af7-4983-92cf-a224c7fd2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doct_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1927053d-1670-49df-8f63-34173a6ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_data = pd.read_csv(\"Disease_Description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc737b01-c96d-4ee9-bc01-1be2f0dd3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# des_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a3f9d-ea97-4caf-8cf7-043a2651a94f",
   "metadata": {},
   "source": [
    "## Test with Unknown Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c29e6ed2-c19d-478e-a885-cfb61da110aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preparing the `test_col` list\n",
    "test_col_symptoms = []\n",
    "for col in data_v.columns:\n",
    "    if col != 'Disease':\n",
    "        test_col_symptoms.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d9c172b-8ba1-4d9f-a8ea-5872d117adba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brittle_nails',\n",
       " 'inflammatory_nails',\n",
       " 'spotting_ urination',\n",
       " 'increased_appetite',\n",
       " 'chills',\n",
       " 'yellow_urine',\n",
       " 'ulcers_on_tongue',\n",
       " 'pus_filled_pimples',\n",
       " 'internal_itching',\n",
       " 'swelling_joints',\n",
       " 'vomiting',\n",
       " 'high_fever',\n",
       " 'stomach_bleeding',\n",
       " 'knee_pain',\n",
       " 'back_pain',\n",
       " 'yellow_crust_ooze',\n",
       " 'redness_of_eyes',\n",
       " 'bruising',\n",
       " 'family_history',\n",
       " 'silver_like_dusting',\n",
       " 'blurred_and_distorted_vision',\n",
       " 'receiving_blood_transfusion',\n",
       " 'swollen_extremeties',\n",
       " 'mild_fever',\n",
       " 'passage_of_gases',\n",
       " 'lethargy',\n",
       " 'headache',\n",
       " 'joint_pain',\n",
       " 'dark_urine',\n",
       " 'congestion',\n",
       " 'mood_swings',\n",
       " 'irritation_in_anus',\n",
       " 'weakness_of_one_body_side',\n",
       " 'bloody_stool',\n",
       " 'red_sore_around_nose',\n",
       " 'skin_rash',\n",
       " 'swelled_lymph_nodes',\n",
       " 'cough',\n",
       " 'nausea',\n",
       " 'yellowing_of_eyes',\n",
       " 'weakness_in_limbs',\n",
       " 'depression',\n",
       " 'sinus_pressure',\n",
       " 'blackheads',\n",
       " 'receiving_unsterile_injections',\n",
       " 'chest_pain',\n",
       " 'distention_of_abdomen',\n",
       " 'pain_during_bowel_movements',\n",
       " 'excessive_hunger',\n",
       " 'visual_disturbances',\n",
       " 'malaise',\n",
       " 'foul_smell_of urine',\n",
       " 'acidity',\n",
       " 'mucoid_sputum',\n",
       " 'abnormal_menstruation',\n",
       " 'constipation',\n",
       " 'anxiety',\n",
       " 'pain_behind_the_eyes',\n",
       " 'polyuria',\n",
       " 'spinning_movements',\n",
       " 'irritability',\n",
       " 'sunken_eyes',\n",
       " 'drying_and_tingling_lips',\n",
       " 'loss_of_smell',\n",
       " 'toxic_look_(typhos)',\n",
       " 'altered_sensorium',\n",
       " 'belly_pain',\n",
       " 'bladder_discomfort',\n",
       " 'phlegm',\n",
       " 'irregular_sugar_level',\n",
       " 'nodal_skin_eruptions',\n",
       " 'obesity',\n",
       " 'fluid_overload',\n",
       " 'continuous_feel_of_urine',\n",
       " 'breathlessness',\n",
       " 'painful_walking',\n",
       " 'fast_heart_rate',\n",
       " 'red_spots_over_body',\n",
       " 'weight_loss',\n",
       " 'dizziness',\n",
       " 'cold_hands_and_feets',\n",
       " 'lack_of_concentration',\n",
       " 'loss_of_appetite',\n",
       " 'rusty_sputum',\n",
       " 'swelling_of_stomach',\n",
       " 'swollen_legs',\n",
       " 'fatigue',\n",
       " 'muscle_weakness',\n",
       " 'continuous_sneezing',\n",
       " 'watering_from_eyes',\n",
       " 'neck_pain',\n",
       " 'palpitations',\n",
       " 'skin_peeling',\n",
       " 'sweating',\n",
       " 'runny_nose',\n",
       " 'itching',\n",
       " 'puffy_face_and_eyes',\n",
       " 'blood_in_sputum',\n",
       " 'yellowish_skin',\n",
       " 'restlessness',\n",
       " 'coma',\n",
       " 'burning_micturition',\n",
       " 'movement_stiffness',\n",
       " 'throat_irritation',\n",
       " 'dehydration',\n",
       " 'diarrhoea',\n",
       " 'swollen_blood_vessels',\n",
       " 'slurred_speech',\n",
       " 'extra_marital_contacts',\n",
       " 'weight_gain',\n",
       " 'stomach_pain',\n",
       " 'blister',\n",
       " 'shivering',\n",
       " 'enlarged_thyroid',\n",
       " 'scurring',\n",
       " 'dischromic _patches',\n",
       " 'acute_liver_failure',\n",
       " 'pain_in_anal_region',\n",
       " 'patches_in_throat',\n",
       " 'cramps',\n",
       " 'abdominal_pain',\n",
       " 'stiff_neck',\n",
       " 'prominent_veins_on_calf',\n",
       " 'unsteadiness',\n",
       " 'loss_of_balance',\n",
       " 'history_of_alcohol_consumption',\n",
       " 'indigestion',\n",
       " 'hip_joint_pain',\n",
       " 'muscle_pain',\n",
       " 'muscle_wasting',\n",
       " 'small_dents_in_nails']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dbc7623-23fa-4730-8541-6d7813d76281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initializing variables\n",
    "test_data = {}\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8d37eed-a4c5-452f-9333-1fa05cf1bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d1bb333-10ae-4cd9-a4bc-52c6500b6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your disease.......     ,   ,    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease you have :     ,   ,    \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Take descipe diseas from the PATIENT\n",
    "text = input(\"Enter your disease.......\")\n",
    "print(\"Disease you have :\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1bf398-6587-4341-a5c5-2c571db8ed28",
   "metadata": {},
   "source": [
    "# Text Translate English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5be657da-e8fa-40c2-9600-065aedbc2519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stomach has been in pain since morning, headache in the afternoon, vomiting at night.\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "# Create an instance of the Translator class\n",
    "translator = Translator()\n",
    "\n",
    "# Translate the text to English (or any desired language)\n",
    "translated = translator.translate(text, dest='en').text\n",
    "\n",
    "# Convert the translated text to lowercase\n",
    "translated = translated.lower()\n",
    "\n",
    "# Print the translated text\n",
    "print(translated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9d999-dca8-4236-98bd-aad793ab62db",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6064ff0-d17d-4cee-8356-c69af2b25a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce6d17d3-8dbe-471f-9aed-ffd395cbe3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stomach',\n",
       " 'has',\n",
       " 'been',\n",
       " 'in',\n",
       " 'pain',\n",
       " 'since',\n",
       " 'morning',\n",
       " 'headache',\n",
       " 'in',\n",
       " 'the',\n",
       " 'afternoon',\n",
       " 'vomiting',\n",
       " 'at',\n",
       " 'night']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the input\n",
    "tokens = re.findall(r'\\b\\w+\\b', translated)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15f1e809-ad3b-46c5-92b1-36352bf2a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "# tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06459c93-9ff3-4812-957c-dfb93b906849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for matches by splitting keywords and comparing with tokens\n",
    "symptoms = []\n",
    "for symptom in test_col_symptoms:\n",
    "    parts = symptom.split('_')\n",
    "    if all(part in tokens for part in parts):\n",
    "        symptoms.append(symptom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58262c89-b9ef-42cd-9ae7-f0743fedd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_col_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34148089-6715-4db2-b80b-cb8129fc5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered words: ['vomiting', 'headache', 'stomach_pain']\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered words:\", symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0efd1f2-c782-4317-96b9-04dd22a2fceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brittle_nails': 0,\n",
       " 'inflammatory_nails': 0,\n",
       " 'spotting_ urination': 0,\n",
       " 'increased_appetite': 0,\n",
       " 'chills': 0,\n",
       " 'yellow_urine': 0,\n",
       " 'ulcers_on_tongue': 0,\n",
       " 'pus_filled_pimples': 0,\n",
       " 'internal_itching': 0,\n",
       " 'swelling_joints': 0,\n",
       " 'vomiting': 1,\n",
       " 'high_fever': 0,\n",
       " 'stomach_bleeding': 0,\n",
       " 'knee_pain': 0,\n",
       " 'back_pain': 0,\n",
       " 'yellow_crust_ooze': 0,\n",
       " 'redness_of_eyes': 0,\n",
       " 'bruising': 0,\n",
       " 'family_history': 0,\n",
       " 'silver_like_dusting': 0,\n",
       " 'blurred_and_distorted_vision': 0,\n",
       " 'receiving_blood_transfusion': 0,\n",
       " 'swollen_extremeties': 0,\n",
       " 'mild_fever': 0,\n",
       " 'passage_of_gases': 0,\n",
       " 'lethargy': 0,\n",
       " 'headache': 1,\n",
       " 'joint_pain': 0,\n",
       " 'dark_urine': 0,\n",
       " 'congestion': 0,\n",
       " 'mood_swings': 0,\n",
       " 'irritation_in_anus': 0,\n",
       " 'weakness_of_one_body_side': 0,\n",
       " 'bloody_stool': 0,\n",
       " 'red_sore_around_nose': 0,\n",
       " 'skin_rash': 0,\n",
       " 'swelled_lymph_nodes': 0,\n",
       " 'cough': 0,\n",
       " 'nausea': 0,\n",
       " 'yellowing_of_eyes': 0,\n",
       " 'weakness_in_limbs': 0,\n",
       " 'depression': 0,\n",
       " 'sinus_pressure': 0,\n",
       " 'blackheads': 0,\n",
       " 'receiving_unsterile_injections': 0,\n",
       " 'chest_pain': 0,\n",
       " 'distention_of_abdomen': 0,\n",
       " 'pain_during_bowel_movements': 0,\n",
       " 'excessive_hunger': 0,\n",
       " 'visual_disturbances': 0,\n",
       " 'malaise': 0,\n",
       " 'foul_smell_of urine': 0,\n",
       " 'acidity': 0,\n",
       " 'mucoid_sputum': 0,\n",
       " 'abnormal_menstruation': 0,\n",
       " 'constipation': 0,\n",
       " 'anxiety': 0,\n",
       " 'pain_behind_the_eyes': 0,\n",
       " 'polyuria': 0,\n",
       " 'spinning_movements': 0,\n",
       " 'irritability': 0,\n",
       " 'sunken_eyes': 0,\n",
       " 'drying_and_tingling_lips': 0,\n",
       " 'loss_of_smell': 0,\n",
       " 'toxic_look_(typhos)': 0,\n",
       " 'altered_sensorium': 0,\n",
       " 'belly_pain': 0,\n",
       " 'bladder_discomfort': 0,\n",
       " 'phlegm': 0,\n",
       " 'irregular_sugar_level': 0,\n",
       " 'nodal_skin_eruptions': 0,\n",
       " 'obesity': 0,\n",
       " 'fluid_overload': 0,\n",
       " 'continuous_feel_of_urine': 0,\n",
       " 'breathlessness': 0,\n",
       " 'painful_walking': 0,\n",
       " 'fast_heart_rate': 0,\n",
       " 'red_spots_over_body': 0,\n",
       " 'weight_loss': 0,\n",
       " 'dizziness': 0,\n",
       " 'cold_hands_and_feets': 0,\n",
       " 'lack_of_concentration': 0,\n",
       " 'loss_of_appetite': 0,\n",
       " 'rusty_sputum': 0,\n",
       " 'swelling_of_stomach': 0,\n",
       " 'swollen_legs': 0,\n",
       " 'fatigue': 0,\n",
       " 'muscle_weakness': 0,\n",
       " 'continuous_sneezing': 0,\n",
       " 'watering_from_eyes': 0,\n",
       " 'neck_pain': 0,\n",
       " 'palpitations': 0,\n",
       " 'skin_peeling': 0,\n",
       " 'sweating': 0,\n",
       " 'runny_nose': 0,\n",
       " 'itching': 0,\n",
       " 'puffy_face_and_eyes': 0,\n",
       " 'blood_in_sputum': 0,\n",
       " 'yellowish_skin': 0,\n",
       " 'restlessness': 0,\n",
       " 'coma': 0,\n",
       " 'burning_micturition': 0,\n",
       " 'movement_stiffness': 0,\n",
       " 'throat_irritation': 0,\n",
       " 'dehydration': 0,\n",
       " 'diarrhoea': 0,\n",
       " 'swollen_blood_vessels': 0,\n",
       " 'slurred_speech': 0,\n",
       " 'extra_marital_contacts': 0,\n",
       " 'weight_gain': 0,\n",
       " 'stomach_pain': 1,\n",
       " 'blister': 0,\n",
       " 'shivering': 0,\n",
       " 'enlarged_thyroid': 0,\n",
       " 'scurring': 0,\n",
       " 'dischromic _patches': 0,\n",
       " 'acute_liver_failure': 0,\n",
       " 'pain_in_anal_region': 0,\n",
       " 'patches_in_throat': 0,\n",
       " 'cramps': 0,\n",
       " 'abdominal_pain': 0,\n",
       " 'stiff_neck': 0,\n",
       " 'prominent_veins_on_calf': 0,\n",
       " 'unsteadiness': 0,\n",
       " 'loss_of_balance': 0,\n",
       " 'history_of_alcohol_consumption': 0,\n",
       " 'indigestion': 0,\n",
       " 'hip_joint_pain': 0,\n",
       " 'muscle_pain': 0,\n",
       " 'muscle_wasting': 0,\n",
       " 'small_dents_in_nails': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Creating `test_data` for prediction\n",
    "for column in test_col_symptoms:\n",
    "    test_data[column] = 1 if column in symptoms else 0\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ba24c0e-2caf-4b52-bc79-810c3cf380ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brittle_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>spotting_ urination</th>\n",
       "      <th>increased_appetite</th>\n",
       "      <th>chills</th>\n",
       "      <th>yellow_urine</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>pus_filled_pimples</th>\n",
       "      <th>internal_itching</th>\n",
       "      <th>swelling_joints</th>\n",
       "      <th>...</th>\n",
       "      <th>stiff_neck</th>\n",
       "      <th>prominent_veins_on_calf</th>\n",
       "      <th>unsteadiness</th>\n",
       "      <th>loss_of_balance</th>\n",
       "      <th>history_of_alcohol_consumption</th>\n",
       "      <th>indigestion</th>\n",
       "      <th>hip_joint_pain</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>muscle_wasting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   brittle_nails  inflammatory_nails  spotting_ urination  increased_appetite  \\\n",
       "0              0                   0                    0                   0   \n",
       "\n",
       "   chills  yellow_urine  ulcers_on_tongue  pus_filled_pimples  \\\n",
       "0       0             0                 0                   0   \n",
       "\n",
       "   internal_itching  swelling_joints  ...  stiff_neck  \\\n",
       "0                 0                0  ...           0   \n",
       "\n",
       "   prominent_veins_on_calf  unsteadiness  loss_of_balance  \\\n",
       "0                        0             0                0   \n",
       "\n",
       "   history_of_alcohol_consumption  indigestion  hip_joint_pain  muscle_pain  \\\n",
       "0                               0            0               0            0   \n",
       "\n",
       "   muscle_wasting  small_dents_in_nails  \n",
       "0               0                     0  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_data, index=[0])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82292d9e-c8da-4c1a-bb1d-f75af9f074b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Disease based on 6 ML algorithms...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Predicting disease using ML models\n",
    "print(\"Predicting Disease based on 6 ML algorithms...\")\n",
    "for model_name, values in models.items():\n",
    "    predict_disease = values[\"model\"].predict(test_df)\n",
    "    predict_disease = le.inverse_transform(predict_disease)\n",
    "    predicted.extend(predict_disease)\n",
    "le "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3139dfdf-4d75-4311-aabc-03273b73e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Calculating disease probability and formatting the result\n",
    "from collections import Counter\n",
    "disease_counts = Counter(predicted)\n",
    "percentage_per_disease = {disease: (count / 6) * 100 for disease, count in disease_counts.items()}\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"Disease\": list(percentage_per_disease.keys()),\n",
    "    \"Chances\": list(percentage_per_disease.values())\n",
    "})\n",
    "\n",
    "# Perform the merges\n",
    "result_df = result_df.merge(doct_data, on='Disease', how='left')\n",
    "result_df = result_df.merge(des_data, on='Disease', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98bbba31-31d9-4d54-af1c-7f8d6fef44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Disease    Chances          Specialist  \\\n",
      "0  Paralysis (brain hemorrhage)  83.333333         Neurologist   \n",
      "1                          GERD  16.666667  Gastroenterologist   \n",
      "\n",
      "                                         Description  \n",
      "0  Intracerebral hemorrhage (ICH) is when blood s...  \n",
      "1  Gastroesophageal reflux disease, or GERD, is a...  \n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa832cf-e305-4725-bf2d-d29b1fd44369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad48fd-2dc5-45dc-98a1-fb7c3cc8510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22482331-3ebe-492f-8597-5227f2b80bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
